# MizBERT
MizBERT is a masked language model (MLM) pre-trained on a corpus of Mizo text data. It is based on the BERT (Bidirectional Encoder Representations from Transformers) architecture and leverages the MLM objective to effectively learn contextual representations of words in the Mizo language.
